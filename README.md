# ğŸ¤– Agentic RAG Chatbot

An intelligent chatbot built with **Agentic RAG** (Retrieval-Augmented Generation) that combines reasoning capabilities with knowledge retrieval to provide accurate, context-aware responses.

**âœ¨ Now with a modern ChatGPT-like web interface!** ğŸŒ

## ğŸŒŸ Features

- **Modern Web Interface**: ChatGPT-inspired UI with dark theme and responsive design ğŸ¨
- **Agentic Behavior**: The chatbot can reason about what information it needs and decide when to use retrieval tools
- **RAG Pipeline**: Combines retrieval from a knowledge base with language model generation
- **Conversation Memory**: Maintains context across the conversation
- **Vector Search**: Uses ChromaDB and OpenAI embeddings for semantic search
- **Extensible Tool System**: Easy to add new tools and capabilities
- **Interactive CLI**: User-friendly command-line interface (legacy mode)

## ğŸ—ï¸ Architecture

The system consists of several key components:

1. **Vector Store Manager**: Handles document loading, chunking, and embedding
2. **Retrieval Tool**: Searches the knowledge base for relevant information
3. **Agentic RAG Agent**: Uses reasoning to decide when and how to use tools
4. **Chatbot Interface**: Manages user interaction and conversation flow

## ğŸ“‹ Prerequisites

- Python 3.8 or higher
- OpenAI API key

## ğŸš€ Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/LalitIITM/Chatbot_agentic_RAG.git
   cd Chatbot_agentic_RAG
   ```

2. **Create a virtual environment** (recommended):
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables**:
   - Copy `.env.example` to `.env`
   - Configure required settings in the `.env` file:
     ```
     OPENAI_API_KEY=your_openai_api_key_here
     SECRET_KEY=your-random-secret-key-here
     ```
   - Generate a secure SECRET_KEY with:
     ```bash
     python -c "import secrets; print(secrets.token_hex(32))"
     ```

## ğŸ“– Usage

### Option 1: Web Interface (Recommended) ğŸŒ

Start the web application with a modern ChatGPT-like interface:
```bash
python app.py
```

Then open your browser and navigate to:
```
http://localhost:5000
```

**Features:**
- Modern, ChatGPT-inspired interface with dark theme
- Real-time chat interactions
- Conversation history management
- Responsive design for desktop and mobile
- Easy-to-use example prompts to get started

**ğŸ“˜ For detailed frontend documentation, screenshots, and customization guide, see [FRONTEND_GUIDE.md](FRONTEND_GUIDE.md)**

### Option 2: Command-Line Interface

Start the traditional CLI chatbot with:
```bash
python chatbot.py
```

### CLI Commands

Once the CLI chatbot is running, you can use these commands:

- Type any question to chat with the bot
- `history` - View the conversation history
- `reset` - Clear the conversation history
- `quit` or `exit` - Exit the chatbot

### Example Interaction

```
You: What is RAG?

ğŸ¤– Assistant: RAG stands for Retrieval-Augmented Generation. It's a technique 
that combines large language models with external knowledge retrieval...

You: How does it work?

ğŸ¤– Assistant: RAG works through several steps: query processing, retrieval phase,
augmentation, and generation...
```

## ğŸ“ Project Structure

```
Chatbot_agentic_RAG/
â”œâ”€â”€ app.py                  # Web application (Flask) - NEW! ğŸŒ
â”œâ”€â”€ chatbot.py              # CLI application entry point
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env.example           # Example environment variables
â”œâ”€â”€ .gitignore             # Git ignore file
â”œâ”€â”€ templates/             # HTML templates for web interface
â”‚   â””â”€â”€ index.html         # Main chat interface
â”œâ”€â”€ data/
â”‚   â””â”€â”€ documents/         # Place your documents here (txt, pdf, md, csv, docx)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ rag_agent.py   # Agentic RAG implementation
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â””â”€â”€ retrieval_tool.py  # Knowledge base search tool
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ vector_store.py    # Document indexing and retrieval
â””â”€â”€ chroma_db/             # Vector database (created automatically)
```

## ğŸ“š Adding Your Own Documents

1. Place your documents in the `data/documents/` directory
2. The chatbot will automatically load and index them on startup
3. The vector store is persisted in `chroma_db/`, so documents are only processed once

**Supported file formats:**
- `.txt` - Plain text files
- `.pdf` - PDF documents
- `.md` - Markdown files
- `.csv` - CSV data files
- `.docx` - Microsoft Word documents

## ğŸ”§ Configuration

You can customize the chatbot by modifying these settings in your `.env` file:

```env
OPENAI_API_KEY=your_api_key_here
OPENAI_MODEL=gpt-3.5-turbo          # Or gpt-4 for better results
EMBEDDING_MODEL=text-embedding-ada-002
```

## ğŸ¯ How It Works

1. **Document Loading**: Documents are loaded from `data/documents/`
2. **Chunking**: Documents are split into smaller chunks for better retrieval
3. **Embedding**: Each chunk is converted to a vector using OpenAI embeddings
4. **Vector Storage**: Embeddings are stored in ChromaDB for fast similarity search
5. **Agent Loop**: When you ask a question:
   - The agent reasons about what information it needs
   - It uses the retrieval tool to search the knowledge base
   - Retrieved context is combined with the query
   - The LLM generates a response based on the context
   - The conversation history is maintained for follow-up questions

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ License

This project is open source and available under the MIT License.

## ğŸ™ Acknowledgments

Built with:
- [LangChain](https://github.com/langchain-ai/langchain) - Framework for LLM applications
- [ChromaDB](https://www.trychroma.com/) - Vector database
- [OpenAI](https://openai.com/) - LLM and embeddings
